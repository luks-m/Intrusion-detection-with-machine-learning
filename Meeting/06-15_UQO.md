# Réunion UQO le 15/06 avec Omer Nguena Timo

### Objectifs pour le 20/06

#### Comprendre les algorithmes caché derrière l'apprentissage et la prédiction par LSTM
L'objectif est d'être capable de refaire l'algo et de l'expliquer avec ses mots, sans avoir à utiliser tensorflow ou PyTorch

```diff
- Backpropagation : comment ce fait réellement le changement des paramètres, poids et biais ?
+ exemple de code : https://www.tensorflow.org/guide/basic_training_loops  
```
```py
# Subtract the gradient scaled by the learning rate
  model.w.assign_sub(learning_rate * dw)
  model.b.assign_sub(learning_rate * db)
```

#### Prédiction par LSTM avec du texte en entrée  
Cela implique de reformater les données en entrées et de leur appliquer un pré-traitement
*Ex : Chatbot qui propose une liste de réponse en lien avec la question, suite de mots proposée par le clavier lors de l'écriture d'un message*

#### Refaire l'entrainement avec LSTM en mettant en entrée des réelles dataset de traces et log d'intrusion
Trouver les dataset, classer les fausses des vraies intrusions, puis entrainer le modèle
*Faire de l'entrainement sur des données de série temporelle pour détection d'intrusions*

#### Regarder ce qu'est Wazuh et selks
Petit résumé + voir si on peut les utiliser

- Lors du parcours des différentes articles : prendre du temps pour écrire ce qu'on a compris de l'article et pouvoir soulever des questions ou remarques.

### Réalisation

#### Qu'est-ce qu'un RNN et LSTM ? Quel est l'algorithme d'apprentissage ?
https://www.geeksforgeeks.org/introduction-to-recurrent-neural-network/?ref=lbp  

https://www.youtube.com/watch?v=EL439RMv3Xc&ab_channel=ThibaultNeveu  
https://www.youtube.com/watch?v=3xgYxrNyE54&ab_channel=ThibaultNeveu  
Vidéos d'explications sur RNN et LSTM

https://www.geeksforgeeks.org/lstm-derivation-of-back-propagation-through-time/?ref=lbp  
Explication de la backpropagation et algotithme de LSTM

https://agustinus.kristia.de/techblog/2016/08/12/lstm-backprop/  
Implémentation d'un algo d'apprentissage avec backpropagation en Python

**Résumé général**  

L'apprentissage de séries temporelles nécessite de garder en mémoire différents états des cellules lors du training.

Ainsi, les Réseaux de Neurones Récurrents permettent cela.

*Analogie avec les réseaux feedforward*  

On note X l'entrée dans le réseau et Y la sortie du réseau. On a alors X -> réseaux -> Y  
Lors de l'apprentissage dans un réseau de base, à chaque étapes on retourne une sortie en fonction de l'entrée uniquement. Cependant pour les séries temporelles, la sortie est prédit en fonction de l'entrée mais également de ce qu'il s'est passé à l'instant t-1.

Par exemple, si on envoie "Comment" dans le réseau, alors celui si va retourner "ça" qui est généralement le mot qui suit "comment" dans les phrases des français. Ensuite si on envoie "ça" dans le réseaux, alors il est difficile pour le réseau de comprendre ce qu'il faut prédire comme il ne connait pas le mot qui était en entrée avant "ça". C'est pourquoi il faut garder en mémoire les états des cellules, c'est ce que fait le réseau récurrent.

On a donc   Xt -> réseaux -> Yt  
                       |  
            Xt+1 -> réseaux -> Yt+1

Ainsi le réseau peut garder en mémoire l'état de la cellule à l'instant t-1 pour prédire la sortie à l'instant t.

*Limite du RNN, utilisation du LSTM*  

Cependant les RNN présentent une limite liée à la descente de gradient. En effet, lors de la backpropagation, le gradientest mulitplié à chaque étape par des valeurs très petites comprises entre 0 et 1 (cela est du à l'utilisation de la fonction d'activation `tanh`). Ainsi le gradient étant très petit, les valeurs des poids et biais ne sont plus modifiées et le réseau de neurone n'apprend plus.

C'est pour cela que l'on utilise le LSTM. Le LSTM permet de garder en mémoire *beaucoup de données à court terme*. En effet, chaque état des cellules est sauvergardé à l'instant t. A l'instant t+1, le LSTM utilise l'état précedent de la cellule mais peut modifier cet état. C'est-à-dire qu'il peut supprimer des informations, en modifier certaines et en ajouter des nouvelles. 

*Fonctionnement du LSTM*

Pour cela, le LSTM utilise 3 portes (gates). La **forget gate** qui définit quelle quantité d'information doit être oubliée, la **input gate** qui définit quelle quantité d'information doit être ajoutée et la **output gate** qui défninit le nouvel état de la cellule à partir des valeurs supprimées et ajoutées.

On peut shématiser une cellule du LSTM (Cf schéma papier). On connait les fonctions d'activation, on initialise les poids avec des valeurs nulles pour la première étape.

*Algorithme d'apprentissage*

On définit un nombre d'époch. A chaque époch, on train sur nos valeurs et on calcul l'erreur puis les différents gradient. Le gradient total est la somme de tous les gradients liés à chaque fonction d'activation (Cf Papier). Ensuite, on modifie la valeur des poids initiaux puis on relance l'apprentissage qui utilisera l'état de la cellule à l'instant t-1 et qui modifiera l'état en sortie avant qu'on recalcule le gradient et ainsi de suite jusqu'à la fin des itérations.

*Utilisation de TensorFlow*

Tensorflow propose ses propres méthodes d'apprentissage et sa propre boucle d'apprentissage avec backpropagation. Cependant, l'outil propose également de modifier certaines parties de la boucle (ou la boucle entière) ainsi que les méthodes d'apprentissage, c'est pourquoi il est très utile.

#### Wazuh
Wazuh est une plateforme d'analyse de sécurité qui permet de détecter les intrusions et les attaques.

#### Selks

#### 