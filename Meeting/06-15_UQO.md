# Réunion UQO le 15/06 avec Omer Nguena Timo

### Objectifs pour le 20/06

#### Prédiction par LSTM avec du texte en entrée  
Cela implique de reformater les données en entrées et de leur appliquer un pré-traitement
*Ex : Chatbot qui propose une liste de réponse en lien avec la question, suite de mots proposée par le clavier lors de l'écriture d'un message*

#### Comprendre les algorithmes caché derrière l'apprentissage et la prédiction par LSTM
L'objectif est d'être capable de refaire l'algo et de l'expliquer avec ses mots, sans avoir à utiliser tensorflow ou PyTorch

#### Refaire l'entrainement avec LSTM en mettant en entrée des réelles dataset de traces et log d'intrusion
Trouver les dataset, classer les fausses des vraies intrusions, puis entrainer le modèle
*Faire de l'entrainement sur des données de série temporelle pour détection d'intrusions*

#### Regarder ce qu'est Wazuh et selks
Petit résumé + voir si on peut les utiliser

- Lors du parcours des différentes articles : prendre du temps pour écrire ce qu'on a compris de l'article et pouvoir soulever des questions ou remarques.

### Réalisation

#### Qu'est-ce qu'un RNN et LSTM ?
https://www.geeksforgeeks.org/introduction-to-recurrent-neural-network/?ref=lbp  

https://www.youtube.com/watch?v=EL439RMv3Xc&ab_channel=ThibaultNeveu  
https://www.youtube.com/watch?v=3xgYxrNyE54&ab_channel=ThibaultNeveu  
Vidéos d'explications sur RNN et LSTM

https://www.geeksforgeeks.org/lstm-derivation-of-back-propagation-through-time/?ref=lbp  
Explication de la backpropagation et algotithme de LSTM

https://agustinus.kristia.de/techblog/2016/08/12/lstm-backprop/  
Implémentation d'un algo d'apprentissage avec backpropagation en Python

**Résumé général**  
